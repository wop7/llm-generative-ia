{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a85fb5b-dc44-42aa-8229-3004c34125f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ae17346-874e-4f66-852a-4e3a5a4d82bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61475fdd-04ed-4ad3-92c2-c9b6a5d92bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b43773-d8ae-4aaf-ab35-dffd685f7eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8423825c-5c1e-4139-b29a-8e84bd6463a4",
   "metadata": {},
   "source": [
    "### Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fbcab38-b140-43ff-9f01-62114d2bc83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = 'key'\n",
    "endpoint = 'endpoint'\n",
    "deployname = 'gpt-4-2-teste'\n",
    "apiversion =  '2024-08-01-preview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6852c0e6-f8ed-45bb-8487-b9dc031864b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AzureOpenAI(\n",
    "    api_key=apikey,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_version=apiversion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8813d472-3b2c-4665-985e-3507fc6d356d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá! Como posso ajudar você hoje?\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\"role\":\"user\",\n",
    "        \"content\":\"Oi\"}\n",
    "    ],\n",
    "    model=deployname,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aadc46-1043-4245-9270-bc6ef7ad2d3a",
   "metadata": {},
   "source": [
    "### Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b92ea5-6133-4d97-bab3-89bd0bfb728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "681c5afa-a478-4bb9-9cb6-e5735d5c6e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configurar o modelo no LangChain\n",
    "model = AzureChatOpenAI(\n",
    "    api_key=apikey,\n",
    "    model=deployname,\n",
    "    azure_endpoint=endpoint,\n",
    "    api_version=apiversion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "065a3741-6e8c-4e2c-94db-4cf80e8704ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar mensagens usando LangChain\n",
    "messages = [\n",
    "    SystemMessage(content=\"Translate the following from English into Italian\"),\n",
    "    HumanMessage(content=\"hi!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06443db1-e141-421c-a8b2-0039f4d74429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamar o modelo usando invoke\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57dc992f-a20a-4631-8a31-457b8d02a8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eedec9d-2bf4-438c-8973-c846c1816a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-6d887a49-a138-4757-adee-a4c5dc734e5a-0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LangChain também tem suporte a input via string\n",
    "model.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "565b732d-66a2-4484-99c7-8e99465af1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I help you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_5603ee5e2e', 'finish_reason': 'stop', 'logprobs': None}, id='run-2d8604d5-0fa6-42d7-8777-8e932d81aa6e-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke([HumanMessage(\"Hello\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da667807-b83b-4ec8-8e91-f1a6031fae19",
   "metadata": {},
   "source": [
    "##### Streaming\n",
    "\n",
    "Refere-se ao processo de enviar as respostas do modelo em partes, ou tokens individuais, em vez de aguardar que o modelo gere toda a resposta antes de enviá-la. Isso é útil em situações onde você deseja exibir resultados parciais para o usuário em tempo real ou processar a saída à medida que ela é gerada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "214d1321-9511-4de3-8d3f-5d2db2f1604f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|C|iao|!||"
     ]
    }
   ],
   "source": [
    "for token in model.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe80ae0b-c3f6-47d9-9cef-9c1e8cb7944e",
   "metadata": {},
   "source": [
    "##### Prompt Templates\n",
    "\n",
    "O conceito de Prompt Templates no LangChain refere-se a uma ferramenta que ajuda a estruturar e formatar as mensagens de entrada para que estejam prontas para serem enviadas ao modelo de linguagem. Isso é particularmente útil quando as mensagens precisam ser personalizadas com base em variáveis fornecidas pelo usuário (como entradas dinâmicas) e transformadas em um formato específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2323e5c5-262f-4ae8-8198-d834dc3d2ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"Translate the following from English into {language}\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_template), (\"user\", \"{text}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f778192-fc10-4a55-8817-5b9d9a25d4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}), HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A entrada para este modelo de prompt é um dicionário\n",
    "prompt = prompt_template.invoke({\"language\": \"Italian\", \"text\": \"hi!\"})\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1023a38c-5d1f-45bd-a289-87e627417984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='Translate the following from English into Italian', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='hi!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Se quisermos acessar as mensagens diretamente, fazemos\n",
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c3364f6-a4e1-467c-b2b8-5039e162f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao!\n"
     ]
    }
   ],
   "source": [
    "#Podemos invocar o modelo de chat no prompt formatado\n",
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
